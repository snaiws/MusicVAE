{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicVAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXtzF64y9z24Y9lxqi8N0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snaiws/MusicVAE/blob/main/MusicVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MusicVAE"
      ],
      "metadata": {
        "id": "mbETGY2OZpnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "ZbY0zPH8Zq0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Tc7VAqNYXjF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import music21\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYbhe9BSmenN",
        "outputId": "4394f163-6180-467d-ee66-2438b5c2f971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "B2-0vclJM_7v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data load\n",
        "train = tfds.load(\n",
        "    name=\"groove/full-midionly\",\n",
        "    split=tfds.Split.TRAIN,\n",
        "    try_gcs=True)\n",
        "test = tfds.load(\n",
        "    name=\"groove/full-midionly\",\n",
        "    split=tfds.Split.TEST,\n",
        "    try_gcs=True)\n",
        "val = tfds.load(\n",
        "    name=\"groove/full-midionly\",\n",
        "    split=tfds.Split.VALIDATION,\n",
        "    try_gcs=True)\n",
        "train = train.shuffle(1024).batch(1).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val = val.shuffle(1024).batch(1).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test = test.shuffle(1024).batch(1).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train = [features[\"midi\"].numpy()[0] for features in train.take(len(train))]\n",
        "val = [features[\"midi\"].numpy()[0] for features in val.take(len(val))]\n",
        "test = [features[\"midi\"].numpy()[0] for features in test.take(len(test))]"
      ],
      "metadata": {
        "id": "HymQeZAyU9dn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train),len(val),len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDbnT3p0ZbhB",
        "outputId": "f9fa900a-6016-4f48-88a4-100c86273423"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(897, 124, 129)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "RCDW1uUuL3Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pitch_conv={\n",
        "    'B-flat0':(22,'IDK1'),\n",
        "    'D1':(26,'IDK2'),\n",
        "    'C2':(36,'Bass Drum 1'),\n",
        "    'C-sharp2':(37,'Side Stick'),\n",
        "    'D2':(38,'Acoustic Snare'),\n",
        "    'E2':(40,'Electric Snare'),\n",
        "    'F-sharp2':(42,'Closed Hi-Hat'),\n",
        "    'G2':(43,'High Floor Tom'),\n",
        "    'G-sharp2':(44,'Pedal Hi-Hat'),\n",
        "    'A2':(45,'Low Tom'),\n",
        "    'B-flat2':(46,'Open Hi-Hat'),\n",
        "    'B2':(47,'Low-Mid Tom'),\n",
        "    'C3':(48,'Hi-Mid Tom'),\n",
        "    'C-sharp3':(49,'Crash Cymbal 1'),\n",
        "    'D3':(50,'High Tom'),\n",
        "    'E-flat3':(51,'Ride Cymbal 1'),\n",
        "    'E3':(52,'Chinese Cymbal'),\n",
        "    'F3':(53,'Ride Bell'),\n",
        "    'G3':(55,'Splash Cymbal'),\n",
        "    'A3':(57,'Crash Cymbal 2'),\n",
        "    'B-flat3':(58,'Vibraslap'),\n",
        "    'B3':(59,'Ride Cymbal 2')\n",
        "}"
      ],
      "metadata": {
        "id": "9wfmEYUFxuOH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pitch_order = {'A2': 9,\n",
        " 'A3': 19,\n",
        " 'B-flat0': 0,\n",
        " 'B-flat2': 10,\n",
        " 'B-flat3': 20,\n",
        " 'B2': 11,\n",
        " 'B3': 21,\n",
        " 'C-sharp2': 3,\n",
        " 'C-sharp3': 13,\n",
        " 'C2': 2,\n",
        " 'C3': 12,\n",
        " 'D1': 1,\n",
        " 'D2': 4,\n",
        " 'D3': 14,\n",
        " 'E-flat3': 15,\n",
        " 'E2': 5,\n",
        " 'E3': 16,\n",
        " 'F-sharp2': 6,\n",
        " 'F3': 17,\n",
        " 'G-sharp2': 8,\n",
        " 'G2': 7,\n",
        " 'G3': 18}"
      ],
      "metadata": {
        "id": "Yxms2sxr0H1-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(midi):\n",
        "    midi = music21.converter.parse(midi)\n",
        "    midi = list(midi.recurse())\n",
        "    res = []\n",
        "    for obj in midi:\n",
        "      try:\n",
        "        if obj.isRest:\n",
        "          for i in range(int(obj.beat*36)):\n",
        "            res.append([0 for _ in range(len(pitch_conv))])\n",
        "        elif obj.isNote:\n",
        "          a = [0 for _ in range(len(pitch_conv))]\n",
        "          b = obj.fullName.split()\n",
        "          b = b[0]+b[3]\n",
        "          a[pitch_order[b]]=1\n",
        "          res.append(a)\n",
        "          for i in range(int(obj.beat*36)-1):\n",
        "            res.append([0 for _ in range(len(pitch_conv))])\n",
        "        elif obj.isChord:\n",
        "          a = [0 for _ in range(len(pitch_conv))]\n",
        "          b = obj.fullName\n",
        "          b = b[b.find('{')+1:b.find('}')]\n",
        "          b= b.split('|')\n",
        "          for i in b:\n",
        "            c=i.split(0)+i.split(3)\n",
        "            a[pitch_order[c]]=1\n",
        "          res.append(a)\n",
        "          for i in range(int(obj.beat*36)-1):\n",
        "            res.append([0 for _ in range(len(pitch_conv))])\n",
        "      except:\n",
        "        try:\n",
        "          if str(obj).split('.')[1]=='meter' and str(obj).split('.')[-1]!='TimeSignature 4/4>':\n",
        "            return 0\n",
        "        except:\n",
        "          continue\n",
        "    return res"
      ],
      "metadata": {
        "id": "iw2AlMjUL5IW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=preprocess(train[5])"
      ],
      "metadata": {
        "id": "DQdCgQFP17Ee"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(list(map(sum,a)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26KpOPFm5W-6",
        "outputId": "31bd98d6-5274-4c3c-b1e7-fd8fe9ef2e03"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## embedding"
      ],
      "metadata": {
        "id": "DlgQnFu85kol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gl2TfczI5of7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils"
      ],
      "metadata": {
        "id": "D5n_C6Kcgdm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, std, beta=0):\n",
        "    logvar = std.pow(2).log()\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    \n",
        "    return BCE + (beta * KLD)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = torch.argmax(y_true, axis=2)\n",
        "    total_num = y_true.shape[0] * y_true.shape[1]\n",
        "    \n",
        "    return torch.sum(y_true == y_pred) / total_num"
      ],
      "metadata": {
        "id": "S8g2kNf6pZfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_sigmoid(epoch, k=20):\n",
        "    return k / (k + np.exp(epoch/k))\n",
        "\n",
        "def kl_annealing(epoch, start, end, rate=0.9):\n",
        "    return end + (start - end)*(rate)**epoch"
      ],
      "metadata": {
        "id": "ESo7JxVjPqUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ARXIrswtPqXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iq8YPU_aPqZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "hzv63tggppdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"MusicVAE Encoder\"\"\"\n",
        "        \n",
        "    def __init__(self, input_size, hidden_size, latent_dim, num_layers=1, bidirectional=True):\n",
        "        \"\"\"Initialize class\n",
        "     \n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size : dim of input sequence\n",
        "        hidden_size : LSTM hidden size\n",
        "        latent_dim : dim of latent z\n",
        "        num_layers : the number of LSTM layers\n",
        "        bidirectional : True or False\n",
        "        \"\"\"\n",
        "            \n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        if bidirectional == True:\n",
        "            num_directions = 2\n",
        "        else:\n",
        "            num_directions = 1\n",
        "            \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden = num_directions * num_layers\n",
        "        self.final_size = self.num_hidden * hidden_size\n",
        "        \n",
        "        self.lstm = nn.LSTM(batch_first=True,\n",
        "                            input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            bidirectional=bidirectional)\n",
        "        \n",
        "        self.mu = nn.Linear(self.final_size, latent_dim)\n",
        "        self.std = nn.Linear(self.final_size, latent_dim)\n",
        "        self.norm = nn.LayerNorm(latent_dim, elementwise_affine=False)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : input sequecne (batch, seq, feat)\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        z : latent z (batch, latent_dim)\n",
        "        mu : mu (batch, latent_dim)\n",
        "        std : std (batch, latent_dim)\n",
        "        \"\"\"\n",
        "        \n",
        "        x, (h, c) = self.lstm(x)\n",
        "        h = h.transpose(0, 1).reshape(-1, self.final_size)\n",
        "        \n",
        "        mu = self.norm(self.mu(h))\n",
        "        std = nn.Softplus()(self.std(h))\n",
        "        \n",
        "        # reparam\n",
        "        z = self.reparameterize(mu, std)\n",
        "        \n",
        "        return z, mu, std\n",
        "    \n",
        "    def reparameterize(self, mu, std):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : mu (batch, latent_dim)\n",
        "        std : std (batch, latent_dim)\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        z : reparam latent z (batch, latent_dim)\n",
        "        \"\"\"\n",
        "            \n",
        "        eps = torch.randn_like(std)\n",
        "\n",
        "        return mu + (eps * std)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : input sequence (batch, seq, feat)\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        z : reparam latent z (batch, latent_dim)\n",
        "        mu : mu (batch, latent_dim)\n",
        "        std : std (batch, latent_dim)\n",
        "        \"\"\"\n",
        "            \n",
        "        z, mu, std = self.encode(x)\n",
        "        \n",
        "        return z, mu, std\n",
        "    \n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"MusicVAE Decoder\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, bidirectional=False):\n",
        "        \"\"\"Initialize class\n",
        "     \n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size : dim of input sequence\n",
        "        hidden_size : dim of LSTM hidden size\n",
        "        output_size : dim of output sequence\n",
        "        num_layers : the number of LSTM layers\n",
        "        bidirectional : True or False\n",
        "        \"\"\"\n",
        "            \n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        if bidirectional == True:\n",
        "            num_directions = 2\n",
        "        else:\n",
        "            num_directions = 1\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_hidden = num_directions * num_layers\n",
        "\n",
        "        self.logits= nn.Linear(hidden_size, output_size)\n",
        "        self.decoder = nn.LSTM(batch_first=True,\n",
        "                               input_size=input_size+output_size,\n",
        "                               hidden_size=hidden_size,\n",
        "                               num_layers=num_layers,\n",
        "                               bidirectional=bidirectional)\n",
        "        \n",
        "    def forward(self, x, h, c, temp=1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : input sequence (batch, 1, feat)\n",
        "        h : LSTM state (num_hidden, batch, hidden_size)\n",
        "        c : LSTM cell (num_hidden, batch, hidden_size)\n",
        "        temp : temperature of softmax\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        out : predicted label (batch, 1, output_size)\n",
        "        prob: predicted prob (batch, 1, output_size)\n",
        "        h : LSTM next state\n",
        "        c : LSTM next cell\n",
        "        \"\"\"\n",
        "        \n",
        "        x, (h, c) = self.decoder(x, (h, c))\n",
        "        logits = self.logits(x) / temp\n",
        "        prob = nn.Softmax(dim=2)(logits)\n",
        "        out = torch.argmax(prob, 2)\n",
        "                \n",
        "        return out, prob, h, c\n",
        "\n",
        "    \n",
        "class Conductor(nn.Module):\n",
        "    \"\"\"MusicVAE Conductor\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, device, num_layers=2, bidirectional=False, bar=4):\n",
        "        \"\"\"Initialize class\n",
        "     \n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size : dim of input sequence\n",
        "        hidden_size : dim of LSTM hidden size\n",
        "        output_size : dim of output sequence\n",
        "        num_layers : the number of LSTM layers\n",
        "        bidirectional : True or False\n",
        "        bar : the number of units in bar\n",
        "        \"\"\"\n",
        "        \n",
        "        super(Conductor, self).__init__()\n",
        "\n",
        "        if bidirectional == True:\n",
        "            num_directions = 2\n",
        "        else:\n",
        "            num_directions = 1\n",
        "\n",
        "        self.bar = bar\n",
        "        self.device = device\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden = num_directions * num_layers\n",
        "        \n",
        "        self.norm = nn.BatchNorm1d(input_size)\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "        self.conductor = nn.LSTM(batch_first=True,\n",
        "                                 input_size=input_size,\n",
        "                                 hidden_size=hidden_size,\n",
        "                                 num_layers=num_layers,\n",
        "                                 bidirectional=bidirectional)\n",
        "        \n",
        "    def init_hidden(self, batch_size, z):\n",
        "        h0 = z.repeat(self.num_hidden, 1, 1)\n",
        "        c0 = z.repeat(self.num_hidden, 1, 1)\n",
        "\n",
        "        return h0, c0\n",
        "    \n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : latent z (batch, input_size)\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        feat : conductor feat (batch, bar_seq, hidden_size)\n",
        "        \"\"\"\n",
        "            \n",
        "        batch_size = z.shape[0]\n",
        "        \n",
        "        z = self.norm(z) # it is different from paper\n",
        "        h, c = self.init_hidden(batch_size, z)\n",
        "        z = z.unsqueeze(1)\n",
        "        \n",
        "        # initialize\n",
        "        feat = torch.zeros(batch_size, self.bar, self.hidden_size, device=self.device)\n",
        "        \n",
        "        # conductor\n",
        "        z_input = z\n",
        "        for i in range(self.bar):\n",
        "            z_input, (h, c) = self.conductor(z_input, (h, c))\n",
        "            feat[:, i, :] = z_input.squeeze()\n",
        "            z_input = z\n",
        "            \n",
        "        feat = self.linear(feat)\n",
        "            \n",
        "        return feat\n",
        "    \n",
        "\n",
        "class Hierarchical_Decoder(nn.Module):\n",
        "    \"\"\"MusicVAE Hierarchical Decoder\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, bidirectional=False):\n",
        "        \"\"\"Initialize class\n",
        "     \n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size : dim of input sequence\n",
        "        hidden_size : dim of LSTM hidden size\n",
        "        output_size : dim of output sequence\n",
        "        num_layers : the number of LSTM layers\n",
        "        bidirectional : True or False\n",
        "        \"\"\"\n",
        "            \n",
        "        super(Hierarchical_Decoder, self).__init__()\n",
        "        \n",
        "        if bidirectional == True:\n",
        "            num_directions = 2\n",
        "        else:\n",
        "            num_directions = 1\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_hidden = num_directions * num_layers\n",
        "        \n",
        "        self.logits= nn.Linear(hidden_size, output_size)\n",
        "        self.decoder = nn.LSTM(batch_first=True,\n",
        "                               input_size=input_size+output_size,\n",
        "                               hidden_size=hidden_size,\n",
        "                               num_layers=num_layers,\n",
        "                               bidirectional=bidirectional)\n",
        "        \n",
        "    def forward(self, x, h, c, z, temp=1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : input sequence (batch, 1, feat)\n",
        "        h : LSTM state (num_hidden, batch, hidden_size)\n",
        "        c : LSTM cell (num_hidden, batch, hidden_size)\n",
        "        z : concat feature\n",
        "        temp : temperature of softmax\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        out : predicted label (batch, 1, output_size)\n",
        "        prob: predicted prob (batch, 1, output_size)\n",
        "        h : LSTM next state\n",
        "        c : LSTM next cell\n",
        "        \"\"\"\n",
        "            \n",
        "        x = torch.cat((x, z.unsqueeze(1)), 2)\n",
        "        \n",
        "        x, (h, c) = self.decoder(x, (h, c))\n",
        "        logits = self.logits(x) / temp\n",
        "        prob = nn.Softmax(dim=2)(logits)\n",
        "        out = torch.argmax(prob, 2)\n",
        "                \n",
        "        return out, prob, h, c"
      ],
      "metadata": {
        "id": "bEczRDCopvhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "xQ5UDcfcggVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_train(device, loss_fn, train_loader, val_loader, model, optimizer, temp=1, epochs=100):\n",
        "    history = {}\n",
        "    history['train_loss'] = []\n",
        "    history['train_acc'] = []\n",
        "    history['val_loss'] = []\n",
        "    history['val_acc'] = []\n",
        "    \n",
        "    encoder, decoder = model\n",
        "    enc_optimizer, dec_optimizer = optimizer\n",
        "    \n",
        "    hidden_size = decoder.hidden_size\n",
        "    num_hidden = decoder.num_hidden\n",
        "    output_size = decoder.output_size\n",
        "    \n",
        "    enc_scheduler = optim.lr_scheduler.CosineAnnealingLR(enc_optimizer, epochs, eta_min=1e-6)\n",
        "    dec_scheduler = optim.lr_scheduler.CosineAnnealingLR(dec_optimizer, epochs, eta_min=1e-6)\n",
        "    \n",
        "    for i in range(1, epochs+1):\n",
        "        start_time = time()\n",
        "        \n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "        \n",
        "        ### train\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        for batch_idx, x_train in enumerate(train_loader):\n",
        "            x_train = x_train.to(device)\n",
        "            \n",
        "            batch_size = x_train.shape[0]\n",
        "            seq_len = x_train.shape[1]\n",
        "            \n",
        "            enc_optimizer.zero_grad()\n",
        "            dec_optimizer.zero_grad()\n",
        "            \n",
        "            # encoder\n",
        "            z, x_train_mu, x_train_std = encoder(x_train)\n",
        "\n",
        "            # initialize\n",
        "            h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "            c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "            \n",
        "            x_train_inputs = torch.zeros((batch_size, 1, x_train.shape[2]), device=device)\n",
        "            x_train_inputs = torch.cat((x_train_inputs, z.unsqueeze(1)), 2)\n",
        "            x_train_label = torch.zeros(x_train.shape[:-1], device=device) # argmax\n",
        "            x_train_prob = torch.zeros(x_train.shape, device=device) # prob\n",
        "\n",
        "            # forward\n",
        "            for j in range(seq_len):\n",
        "                label, prob, h, c = decoder(x_train_inputs, h, c, temp=1)\n",
        "\n",
        "                x_train_label[:, j] = label.squeeze()\n",
        "                x_train_prob[:, j, :] = prob.squeeze()\n",
        "                \n",
        "                # scheduled sampling\n",
        "                if np.random.binomial(1, inverse_sigmoid(i)):\n",
        "                    # teacher forcing\n",
        "                    x_train_inputs = torch.cat((x_train[:, j, :], z), 1).unsqueeze(1)\n",
        "                else:\n",
        "                    # sampling\n",
        "                    label = F.one_hot(label, num_classes=output_size)\n",
        "                    x_train_inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
        "            \n",
        "            # loss\n",
        "            beta = kl_annealing(i, 0, 0.2)\n",
        "            loss = loss_fn(x_train_prob, x_train, x_train_mu, x_train_std, beta)\n",
        "            \n",
        "            # backward\n",
        "            loss.backward()\n",
        "            enc_optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            train_acc += accuracy(x_train, x_train_label).item()\n",
        "            \n",
        "        enc_scheduler.step()\n",
        "        dec_scheduler.step()\n",
        "        \n",
        "        train_loss = train_loss / (batch_idx + 1)\n",
        "        train_acc = train_acc / (batch_idx + 1)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        \n",
        "        ### validation\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, x_val in enumerate(val_loader):\n",
        "                x_val = x_val.to(device)\n",
        "                \n",
        "                batch_size = x_val.shape[0]\n",
        "                seq_len = x_val.shape[1]\n",
        "                \n",
        "                # forward encoder\n",
        "                z, x_val_mu, x_val_std = encoder(x_val)\n",
        "                \n",
        "                # initialize\n",
        "                h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                \n",
        "                # full sampling\n",
        "                x_val_inputs = torch.zeros((batch_size, 1, x_val.shape[2]), device=device)\n",
        "                x_val_inputs = torch.cat((x_val_inputs, z.unsqueeze(1)), 2)\n",
        "                x_val_label = torch.zeros(x_val.shape[:-1], device=device) # argmax\n",
        "                x_val_prob = torch.zeros(x_val.shape, device=device) # prob\n",
        "                \n",
        "                # forward\n",
        "                for j in range(seq_len):\n",
        "                    label, prob, h, c = decoder(x_val_inputs, h, c, temp=1)\n",
        "                    \n",
        "                    x_val_label[:, j] = label.squeeze()\n",
        "                    x_val_prob[:, j, :] = prob.squeeze()\n",
        "                    \n",
        "                    label = F.one_hot(label, num_classes=output_size)\n",
        "                    x_val_inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
        "                \n",
        "                loss = loss_fn(x_val_prob, x_val, x_val_mu, x_val_std, beta)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                val_acc += accuracy(x_val, x_val_label).item()\n",
        "                \n",
        "        val_loss = val_loss / (batch_idx + 1)\n",
        "        val_acc = val_acc / (batch_idx + 1)\n",
        "        \n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'] .append(val_acc)\n",
        "        \n",
        "        print('Epoch %d (%0.2f sec) - train_loss: %0.3f, train_acc: %0.3f, val_loss: %0.3f, val_acc: %0.3f, lr: %0.6f' % \\\n",
        "             (i, time()-start_time, train_loss, train_acc, val_loss, val_acc, enc_scheduler.get_last_lr()[0]))\n",
        "        \n",
        "    return history\n",
        "\n",
        "\n",
        "def hierarchical_train(device, loss_fn, train_loader, val_loader, model, optimizer, bar_units=16, epochs=100):\n",
        "    history = {}\n",
        "    history['train_loss'] = []\n",
        "    history['train_acc'] = []\n",
        "    history['val_loss'] = []\n",
        "    history['val_acc'] = []\n",
        "    \n",
        "    encoder, conductor, decoder = model\n",
        "    enc_optimizer, con_optimizer, dec_optimizer = optimizer\n",
        "    \n",
        "    hidden_size = decoder.hidden_size\n",
        "    num_hidden = decoder.num_hidden\n",
        "    output_size = decoder.output_size\n",
        "    \n",
        "    enc_scheduler = optim.lr_scheduler.CosineAnnealingLR(enc_optimizer, epochs, eta_min=1e-6)\n",
        "    con_scheduler = optim.lr_scheduler.CosineAnnealingLR(con_optimizer, epochs, eta_min=1e-6)\n",
        "    dec_scheduler = optim.lr_scheduler.CosineAnnealingLR(dec_optimizer, epochs, eta_min=1e-6)\n",
        "    \n",
        "    for i in range(1, epochs+1):\n",
        "        start_time = time()\n",
        "        \n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "        \n",
        "        encoder.train()\n",
        "        conductor.train()\n",
        "        decoder.train()\n",
        "        for batch_idx, x_train in enumerate(train_loader):\n",
        "            x_train = x_train.to(device)\n",
        "            \n",
        "            batch_size = x_train.shape[0]\n",
        "            seq_len = x_train.shape[1]\n",
        "            \n",
        "            enc_optimizer.zero_grad()\n",
        "            con_optimizer.zero_grad()\n",
        "            dec_optimizer.zero_grad()\n",
        "            \n",
        "            # forward\n",
        "            x_train_z, x_train_mu, x_train_std = encoder(x_train)\n",
        "            x_train_feat = conductor(x_train_z)\n",
        "            \n",
        "            # initialize    \n",
        "            x_train_inputs = torch.zeros((batch_size, 1, x_train.shape[2]), device=device)\n",
        "            x_train_label = torch.zeros(x_train.shape[:-1], device=device) # argmax\n",
        "            x_train_prob = torch.zeros(x_train.shape, device=device) # prob\n",
        "            \n",
        "            # teacher forcing\n",
        "            for j in range(seq_len):\n",
        "                bar_idx = j // bar_units\n",
        "                bar_change_idx = j % bar_units\n",
        "                \n",
        "                z = x_train_feat[:, bar_idx, :]\n",
        "                \n",
        "                # init state\n",
        "                if bar_change_idx == 0:\n",
        "                    h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                    c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                \n",
        "                label, prob, h, c = decoder(x_train_inputs, h, c, z)\n",
        "                \n",
        "                x_train_label[:, j] = label.squeeze()\n",
        "                x_train_prob[:, j, :] = prob.squeeze()\n",
        "                \n",
        "                # teacher forcing\n",
        "                if np.random.binomial(1, inverse_sigmoid(i)):\n",
        "                    x_train_inputs = x_train[:, j, :].unsqueeze(1)\n",
        "                else:\n",
        "                    x_train_inputs = F.one_hot(label, num_classes=output_size)\n",
        "            \n",
        "            beta = kl_annealing(i, 0, 0.2)\n",
        "            loss = loss_fn(x_train_prob, x_train, x_train_mu, x_train_std, beta)\n",
        "            \n",
        "            # backward\n",
        "            loss.backward()\n",
        "            enc_optimizer.step()\n",
        "            con_optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            train_acc += accuracy(x_train, x_train_label).item()\n",
        "            \n",
        "        enc_scheduler.step()\n",
        "        con_scheduler.step()\n",
        "        dec_scheduler.step()\n",
        "        \n",
        "        train_loss = train_loss / (batch_idx + 1)\n",
        "        train_acc = train_acc / (batch_idx + 1)\n",
        "        \n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        \n",
        "        encoder.eval()\n",
        "        conductor.eval()\n",
        "        decoder.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, x_val in enumerate(val_loader):\n",
        "                x_val = x_val.to(device)\n",
        "                \n",
        "                batch_size = x_val.shape[0]\n",
        "                seq_len = x_val.shape[1]\n",
        "                \n",
        "                # forward\n",
        "                x_val_z, x_val_mu, x_val_std = encoder(x_val)\n",
        "                x_val_feat = conductor(x_val_z)\n",
        "                \n",
        "                # initialize\n",
        "                x_val_inputs = torch.zeros((batch_size, 1, x_val.shape[2]), device=device)  \n",
        "                x_val_label = torch.zeros(x_val.shape[:-1], device=device) # argmax\n",
        "                x_val_prob = torch.zeros(x_val.shape, device=device) # prob\n",
        "                \n",
        "                # full sampling\n",
        "                for j in range(seq_len):\n",
        "                    bar_idx = j // bar_units\n",
        "                    bar_change_idx = j % bar_units\n",
        "                    \n",
        "                    z = x_val_feat[:, bar_idx, :]\n",
        "                \n",
        "                    # init state\n",
        "                    if bar_change_idx == 0:\n",
        "                        h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                        c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                    \n",
        "                    label, prob, h, c = decoder(x_val_inputs, h, c, z)\n",
        "\n",
        "                    x_val_label[:, j] = label.squeeze()\n",
        "                    x_val_prob[:, j, :] = prob.squeeze()\n",
        "\n",
        "                    # full sampling\n",
        "                    x_val_inputs = F.one_hot(label, num_classes=output_size)\n",
        "            \n",
        "                loss = loss_fn(x_val_prob, x_val, x_val_mu, x_val_std)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                val_acc += accuracy(x_val, x_val_label).item()\n",
        "                \n",
        "        val_loss = val_loss / (batch_idx + 1)\n",
        "        val_acc = val_acc / (batch_idx + 1)\n",
        "        \n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        \n",
        "        print('Epoch %d (%0.2f sec) - train_loss: %0.3f, train_acc: %0.3f, val_loss: %0.3f, val_acc: %0.3f, lr: %0.6f' % \\\n",
        "             (i, time()-start_time, train_loss, train_acc, val_loss, val_acc, enc_scheduler.get_last_lr()[0]))\n",
        "        \n",
        "    return history"
      ],
      "metadata": {
        "id": "9pKH2UdxpZxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "NjdmubH-PZHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_test(device, loss_fn, test_loader, model, temp=1, options='teacher_forcing'):\n",
        "    history = {}\n",
        "    history['test_loss'] = []\n",
        "    history['test_acc'] = []\n",
        "    \n",
        "    encoder, decoder = model\n",
        "    \n",
        "    start_time = time()\n",
        "\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    \n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    num_hidden = decoder.num_hidden\n",
        "    hidden_size = decoder.hidden_size\n",
        "    output_size = decoder.output_size\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, x_test in enumerate(test_loader):\n",
        "            x_test = x_test.to(device)\n",
        "            \n",
        "            batch_size = x_test.shape[0]\n",
        "            seq_len = x_test.shape[1]\n",
        "\n",
        "            # forward\n",
        "            z, x_test_mu, x_test_std = encoder(x_test)\n",
        "            \n",
        "            h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "            c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "            \n",
        "            x_test_inputs = torch.zeros((batch_size, 1, x_test.shape[2]), device=device)\n",
        "            x_test_inputs = torch.cat((x_test_inputs, z.unsqueeze(1)), 2)\n",
        "            x_test_label = torch.zeros(x_test.shape[:-1], device=device) # argmax\n",
        "            x_test_prob = torch.zeros(x_test.shape, device=device) # prob\n",
        "            \n",
        "            for j in range(seq_len):\n",
        "                label, prob, h, c = decoder(x_test_inputs, h, c, temp=temp)\n",
        "\n",
        "                x_test_label[:, j] = label.squeeze()\n",
        "                x_test_prob[:, j, :] = prob.squeeze()\n",
        "                \n",
        "                if options == 'teacher_forcing':\n",
        "                    x_test_inputs = torch.cat((x_test[:, j, :], z), 1).unsqueeze(1)\n",
        "                else:\n",
        "                    label = F.one_hot(label, num_classes=output_size)\n",
        "                    x_test_inputs = torch.cat((label, z.unsqueeze(1)), 2)\n",
        "\n",
        "            loss = loss_fn(x_test_prob, x_test, x_test_mu, x_test_std)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_acc += accuracy(x_test, x_test_label).item()\n",
        "            \n",
        "            if batch_idx % 10000 == 0:\n",
        "                y_true.append(x_test.data.cpu().numpy())\n",
        "                y_pred.append(x_test_prob.data.cpu().numpy())\n",
        "\n",
        "    test_loss = test_loss / (batch_idx + 1)\n",
        "    test_acc = test_acc / (batch_idx + 1)\n",
        "\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'] .append(test_acc)\n",
        "\n",
        "    print('(%0.2f sec) - test_loss: %0.3f, test_acc: %0.3f' % (time()-start_time, test_loss, test_acc))\n",
        "        \n",
        "    return history, np.vstack(y_true), np.vstack(y_pred)\n",
        "\n",
        "\n",
        "def hierarchical_test(device, loss_fn, test_loader, model, temp=1, bar_units=16, options='teacher_forcing'):\n",
        "    history = {}\n",
        "    history['test_loss'] = []\n",
        "    history['test_acc'] = []\n",
        "    \n",
        "    encoder, conductor, decoder = model\n",
        "    \n",
        "    start_time = time()\n",
        "\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    \n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    encoder.eval()\n",
        "    conductor.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    num_hidden = decoder.num_hidden\n",
        "    hidden_size = decoder.hidden_size\n",
        "    output_size = decoder.output_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, x_test in enumerate(test_loader):\n",
        "            x_test = x_test.to(device)\n",
        "            batch_size = x_test.shape[0]\n",
        "            seq_len = x_test.shape[1]\n",
        "\n",
        "            # forward\n",
        "            x_test_z, x_test_mu, x_test_std = encoder(x_test)\n",
        "            x_test_feat = conductor(x_test_z)\n",
        "            \n",
        "            # initialize\n",
        "            x_test_inputs = torch.zeros((batch_size, 1, x_test.shape[2]), device=device)\n",
        "            x_test_label = torch.zeros(x_test.shape[:-1], device=device) # argmax\n",
        "            x_test_prob = torch.zeros(x_test.shape, device=device) # prob\n",
        "            \n",
        "            for j in range(seq_len):\n",
        "                bar_idx = j // bar_units\n",
        "                bar_change_idx = j % bar_units\n",
        "\n",
        "                z = x_test_feat[:, bar_idx, :]\n",
        "\n",
        "                # init state\n",
        "                if bar_change_idx == 0:\n",
        "                    h = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "                    c = z.repeat(num_hidden, 1, int(hidden_size/z.shape[1]))\n",
        "\n",
        "                label, prob, h, c = decoder(x_test_inputs, h, c, z)\n",
        "\n",
        "                x_test_label[:, j] = label.squeeze()\n",
        "                x_test_prob[:, j, :] = prob.squeeze()\n",
        "                \n",
        "                if options == 'teacher_forcing':\n",
        "                    x_test_inputs = x_test[:, j, :].unsqueeze(1)\n",
        "                else:\n",
        "                    x_test_inputs = F.one_hot(label, num_classes=output_size)\n",
        "\n",
        "            loss = loss_fn(x_test_prob, x_test, x_test_mu, x_test_std)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_acc += accuracy(x_test, x_test_label).item()\n",
        "            \n",
        "            if batch_idx % 10000 == 0:\n",
        "                y_true.append(x_test.data.cpu().numpy())\n",
        "                y_pred.append(x_test_prob.data.cpu().numpy())\n",
        "\n",
        "    test_loss = test_loss / (batch_idx + 1)\n",
        "    test_acc = test_acc / (batch_idx + 1)\n",
        "\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'] .append(test_acc)\n",
        "\n",
        "    print('(%0.2f sec) - test_loss: %0.3f, test_acc: %0.3f' % (time()-start_time, test_loss, test_acc))\n",
        "        \n",
        "    return history, np.vstack(y_true), np.vstack(y_pred)"
      ],
      "metadata": {
        "id": "wLrK914RPap4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "tPo3F6Jxghzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AT4VOKMdpaKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}